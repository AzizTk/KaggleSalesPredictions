{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3d32413e",
   "metadata": {
    "papermill": {
     "duration": 0.007155,
     "end_time": "2022-10-07T20:26:28.522080",
     "exception": false,
     "start_time": "2022-10-07T20:26:28.514925",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Hello again :D, This is another try in Kaggle, This one however is a bit more advanced than usual after checking out the data sets as well as the predictions needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca36b94",
   "metadata": {
    "papermill": {
     "duration": 0.005546,
     "end_time": "2022-10-07T20:26:28.533739",
     "exception": false,
     "start_time": "2022-10-07T20:26:28.528193",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size=\"5\">**Data loading and preprocessing, utility function definition**</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "289970d9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:28.548812Z",
     "iopub.status.busy": "2022-10-07T20:26:28.547767Z",
     "iopub.status.idle": "2022-10-07T20:26:29.641255Z",
     "shell.execute_reply": "2022-10-07T20:26:29.640123Z"
    },
    "papermill": {
     "duration": 1.104262,
     "end_time": "2022-10-07T20:26:29.644231",
     "exception": false,
     "start_time": "2022-10-07T20:26:28.539969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac00e630",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:29.658621Z",
     "iopub.status.busy": "2022-10-07T20:26:29.657908Z",
     "iopub.status.idle": "2022-10-07T20:26:29.672706Z",
     "shell.execute_reply": "2022-10-07T20:26:29.671826Z"
    },
    "papermill": {
     "duration": 0.02507,
     "end_time": "2022-10-07T20:26:29.675317",
     "exception": false,
     "start_time": "2022-10-07T20:26:29.650247",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_mem_usage(df, silent=True, allow_categorical=True, float_dtype=\"float32\"):\n",
    "    \"\"\" \n",
    "    Iterates through all the columns of a dataframe and downcasts the data type\n",
    "     to reduce memory usage. Can also factorize categorical columns to integer dtype.\n",
    "    \"\"\"\n",
    "    def _downcast_numeric(series, allow_categorical=allow_categorical):\n",
    "        \"\"\"\n",
    "        Downcast a numeric series into either the smallest possible int dtype or a specified float dtype.\n",
    "        \"\"\"\n",
    "        if pd.api.types.is_sparse(series.dtype) is True:\n",
    "            return series\n",
    "        elif pd.api.types.is_numeric_dtype(series.dtype) is False:\n",
    "            if pd.api.types.is_datetime64_any_dtype(series.dtype):\n",
    "                return series\n",
    "            else:\n",
    "                if allow_categorical:\n",
    "                    return series\n",
    "                else:\n",
    "                    codes, uniques = series.factorize()\n",
    "                    series = pd.Series(data=codes, index=series.index)\n",
    "                    series = _downcast_numeric(series)\n",
    "                    return series\n",
    "        else:\n",
    "            series = pd.to_numeric(series, downcast=\"integer\")\n",
    "        if pd.api.types.is_float_dtype(series.dtype):\n",
    "            series = series.astype(float_dtype)\n",
    "        return series\n",
    "\n",
    "    if silent is False:\n",
    "        start_mem = np.sum(df.memory_usage()) / 1024 ** 2\n",
    "        print(\"Memory usage of dataframe is {:.2f} MB\".format(start_mem))\n",
    "    if df.ndim == 1:\n",
    "        df = _downcast_numeric(df)\n",
    "    else:\n",
    "        for col in df.columns:\n",
    "            df.loc[:, col] = _downcast_numeric(df.loc[:,col])\n",
    "    if silent is False:\n",
    "        end_mem = np.sum(df.memory_usage()) / 1024 ** 2\n",
    "        print(\"Memory usage after optimization is: {:.2f} MB\".format(end_mem))\n",
    "        print(\"Decreased by {:.1f}%\".format(100 * (start_mem - end_mem) / start_mem))\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "def shrink_mem_new_cols(matrix, oldcols=None, allow_categorical=False):\n",
    "    # Calls reduce_mem_usage on columns which have not yet been optimized\n",
    "    if oldcols is not None:\n",
    "        newcols = matrix.columns.difference(oldcols)\n",
    "    else:\n",
    "        newcols = matrix.columns\n",
    "    matrix.loc[:,newcols] = reduce_mem_usage(matrix.loc[:,newcols], allow_categorical=allow_categorical)\n",
    "    oldcols = matrix.columns  # This is used to track which columns have already been downcast\n",
    "    return matrix, oldcols\n",
    "\n",
    "\n",
    "def list_if_not(s, dtype=str):\n",
    "    # Puts a variable in a list if it is not already a list\n",
    "    if type(s) not in (dtype, list):\n",
    "        raise TypeError\n",
    "    if (s != \"\") & (type(s) is not list):\n",
    "        s = [s]\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cef00f8",
   "metadata": {
    "papermill": {
     "duration": 0.005569,
     "end_time": "2022-10-07T20:26:29.686801",
     "exception": false,
     "start_time": "2022-10-07T20:26:29.681232",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "563ab9cb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:29.701089Z",
     "iopub.status.busy": "2022-10-07T20:26:29.700410Z",
     "iopub.status.idle": "2022-10-07T20:26:32.358331Z",
     "shell.execute_reply": "2022-10-07T20:26:32.357116Z"
    },
    "papermill": {
     "duration": 2.668358,
     "end_time": "2022-10-07T20:26:32.361171",
     "exception": false,
     "start_time": "2022-10-07T20:26:29.692813",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "items = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/items.csv\")\n",
    "shops = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/shops.csv\")\n",
    "train = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/sales_train.csv\")\n",
    "test = pd.read_csv(\"../input/competitive-data-science-predict-future-sales/test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0689fbd",
   "metadata": {
    "papermill": {
     "duration": 0.005543,
     "end_time": "2022-10-07T20:26:32.372755",
     "exception": false,
     "start_time": "2022-10-07T20:26:32.367212",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Converting to dtypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "254a976e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:32.386589Z",
     "iopub.status.busy": "2022-10-07T20:26:32.385622Z",
     "iopub.status.idle": "2022-10-07T20:26:32.826134Z",
     "shell.execute_reply": "2022-10-07T20:26:32.825165Z"
    },
    "papermill": {
     "duration": 0.45073,
     "end_time": "2022-10-07T20:26:32.829240",
     "exception": false,
     "start_time": "2022-10-07T20:26:32.378510",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train[\"date\"] = pd.to_datetime(train[\"date\"], format=\"%d.%m.%Y\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d955e52",
   "metadata": {
    "papermill": {
     "duration": 0.005512,
     "end_time": "2022-10-07T20:26:32.840711",
     "exception": false,
     "start_time": "2022-10-07T20:26:32.835199",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<font size = 5 ><b>DATA CLEANING</b> </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cc8a5b45",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:32.854573Z",
     "iopub.status.busy": "2022-10-07T20:26:32.853618Z",
     "iopub.status.idle": "2022-10-07T20:26:33.275844Z",
     "shell.execute_reply": "2022-10-07T20:26:33.274846Z"
    },
    "papermill": {
     "duration": 0.432006,
     "end_time": "2022-10-07T20:26:33.278479",
     "exception": false,
     "start_time": "2022-10-07T20:26:32.846473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Merge some duplicate shops\n",
    "train[\"shop_id\"] = train[\"shop_id\"].replace({0: 57, 1: 58, 11: 10, 40: 39})\n",
    "# Keep only shops that are in the test set\n",
    "train = train.loc[train.shop_id.isin(test[\"shop_id\"].unique()), :]\n",
    "# Drop training items with extreme or negative prices or sales counts\n",
    "train = train[(train[\"item_price\"] > 0) & (train[\"item_price\"] < 50000)]\n",
    "train = train[(train[\"item_cnt_day\"] > 0) & (train[\"item_cnt_day\"] < 1000)]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9e31d56",
   "metadata": {
    "papermill": {
     "duration": 0.00551,
     "end_time": "2022-10-07T20:26:33.289860",
     "exception": false,
     "start_time": "2022-10-07T20:26:33.284350",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "The test data is every combination of shops and items that had a sale in the test month,the target as the total month's sales made for each of these shop-item combinations. I created a  training matrix that is made to replicate this structure for every month in the training data period. The test items are concatenated to the end of the training data so that features can be generated for the test period."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dda1eab7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:33.303990Z",
     "iopub.status.busy": "2022-10-07T20:26:33.303572Z",
     "iopub.status.idle": "2022-10-07T20:26:33.315971Z",
     "shell.execute_reply": "2022-10-07T20:26:33.314734Z"
    },
    "papermill": {
     "duration": 0.021746,
     "end_time": "2022-10-07T20:26:33.318353",
     "exception": false,
     "start_time": "2022-10-07T20:26:33.296607",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_testlike_train(sales_train, test=None):\n",
    "    indexlist = []\n",
    "    for i in sales_train.date_block_num.unique():\n",
    "        x = itertools.product(\n",
    "            [i],\n",
    "            sales_train.loc[sales_train.date_block_num == i].shop_id.unique(),\n",
    "            sales_train.loc[sales_train.date_block_num == i].item_id.unique(),\n",
    "        )\n",
    "        indexlist.append(np.array(list(x)))\n",
    "    df = pd.DataFrame(\n",
    "        data=np.concatenate(indexlist, axis=0),\n",
    "        columns=[\"date_block_num\", \"shop_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    # Add revenue column to sales_train\n",
    "    sales_train[\"item_revenue_day\"] = sales_train[\"item_price\"] * sales_train[\"item_cnt_day\"]\n",
    "    # Aggregate item_id / shop_id item_cnts and revenue at the month level\n",
    "    sales_train_grouped = sales_train.groupby([\"date_block_num\", \"shop_id\", \"item_id\"]).agg(\n",
    "        item_cnt_month=pd.NamedAgg(column=\"item_cnt_day\", aggfunc=\"sum\"),\n",
    "        item_revenue_month=pd.NamedAgg(column=\"item_revenue_day\", aggfunc=\"sum\"),\n",
    "    )\n",
    "\n",
    "    # Merge the grouped data with the index\n",
    "    df = df.merge(\n",
    "        sales_train_grouped, how=\"left\", on=[\"date_block_num\", \"shop_id\", \"item_id\"],\n",
    "    )\n",
    "\n",
    "    if test is not None:\n",
    "        test[\"date_block_num\"] = 34\n",
    "        test[\"date_block_num\"] = test[\"date_block_num\"].astype(np.int8)\n",
    "        test[\"shop_id\"] = test.shop_id.astype(np.int8)\n",
    "        test[\"item_id\"] = test.item_id.astype(np.int16)\n",
    "        test = test.drop(columns=\"ID\")\n",
    "\n",
    "        df = pd.concat([df, test[[\"date_block_num\", \"shop_id\", \"item_id\"]]])\n",
    "\n",
    "    # Fill empty item_cnt entries with 0\n",
    "    df.item_cnt_month = df.item_cnt_month.fillna(0)\n",
    "    df.item_revenue_month = df.item_revenue_month.fillna(0)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2f22b44c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:33.331620Z",
     "iopub.status.busy": "2022-10-07T20:26:33.331210Z",
     "iopub.status.idle": "2022-10-07T20:26:45.075504Z",
     "shell.execute_reply": "2022-10-07T20:26:45.074276Z"
    },
    "papermill": {
     "duration": 11.753999,
     "end_time": "2022-10-07T20:26:45.078128",
     "exception": false,
     "start_time": "2022-10-07T20:26:33.324129",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "matrix = create_testlike_train(train, test)\n",
    "del(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029038f5",
   "metadata": {
    "papermill": {
     "duration": 0.005457,
     "end_time": "2022-10-07T20:26:45.089406",
     "exception": false,
     "start_time": "2022-10-07T20:26:45.083949",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We need to reduce memory usage through the function previously created, preventing memory overflows & leaks through errors in the kaggle notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "86ad0bd2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:45.102280Z",
     "iopub.status.busy": "2022-10-07T20:26:45.101870Z",
     "iopub.status.idle": "2022-10-07T20:26:46.543897Z",
     "shell.execute_reply": "2022-10-07T20:26:46.542560Z"
    },
    "papermill": {
     "duration": 1.451768,
     "end_time": "2022-10-07T20:26:46.546798",
     "exception": false,
     "start_time": "2022-10-07T20:26:45.095030",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 405.44 MB\n",
      "Memory usage after optimization is: 152.04 MB\n",
      "Decreased by 62.5%\n"
     ]
    }
   ],
   "source": [
    "matrix = reduce_mem_usage(matrix, silent=False)\n",
    "oldcols = matrix.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76743cd6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:46.561381Z",
     "iopub.status.busy": "2022-10-07T20:26:46.560485Z",
     "iopub.status.idle": "2022-10-07T20:26:46.582683Z",
     "shell.execute_reply": "2022-10-07T20:26:46.581445Z"
    },
    "papermill": {
     "duration": 0.032357,
     "end_time": "2022-10-07T20:26:46.585433",
     "exception": false,
     "start_time": "2022-10-07T20:26:46.553076",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>item_name</th>\n",
       "      <th>item_id</th>\n",
       "      <th>item_category_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3565</th>\n",
       "      <td>Fuse [PS3, английская версия]</td>\n",
       "      <td>3565</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3566</th>\n",
       "      <td>Fuse [Xbox 360, английская версия]</td>\n",
       "      <td>3566</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3567</th>\n",
       "      <td>G Data Internet Security 2013 (1ПК / 1 год) (G...</td>\n",
       "      <td>3567</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3568</th>\n",
       "      <td>G Data Internet Security 2013 (3ПК / 1 год) (G...</td>\n",
       "      <td>3568</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3569</th>\n",
       "      <td>GABIN  The Best Of Gabin  2CD</td>\n",
       "      <td>3569</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              item_name  item_id  \\\n",
       "3565                      Fuse [PS3, английская версия]     3565   \n",
       "3566                 Fuse [Xbox 360, английская версия]     3566   \n",
       "3567  G Data Internet Security 2013 (1ПК / 1 год) (G...     3567   \n",
       "3568  G Data Internet Security 2013 (3ПК / 1 год) (G...     3568   \n",
       "3569                      GABIN  The Best Of Gabin  2CD     3569   \n",
       "\n",
       "      item_category_id  \n",
       "3565                19  \n",
       "3566                23  \n",
       "3567                76  \n",
       "3568                76  \n",
       "3569                55  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items.query(\"item_id>3564\").head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23696a97",
   "metadata": {
    "papermill": {
     "duration": 0.00574,
     "end_time": "2022-10-07T20:26:46.597592",
     "exception": false,
     "start_time": "2022-10-07T20:26:46.591852",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "I noticed that items in the table are ordered alphabetically according to the item_name field, So similar items are listed together. We can use this ordering to group together related items "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb68231e",
   "metadata": {
    "papermill": {
     "duration": 0.005838,
     "end_time": "2022-10-07T20:26:46.609380",
     "exception": false,
     "start_time": "2022-10-07T20:26:46.603542",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We can run measure similarities between items and group them together, using a py package called fuzzywuzzy, and asign items to a group if their match value are above a certain threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8979e858",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:46.623826Z",
     "iopub.status.busy": "2022-10-07T20:26:46.622818Z",
     "iopub.status.idle": "2022-10-07T20:26:56.466304Z",
     "shell.execute_reply": "2022-10-07T20:26:56.465246Z"
    },
    "papermill": {
     "duration": 9.853578,
     "end_time": "2022-10-07T20:26:56.469000",
     "exception": false,
     "start_time": "2022-10-07T20:26:46.615422",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "\n",
    "def add_item_name_groups(matrix, train, items, sim_thresh, feature_name=\"item_name_group\"):\n",
    "    def partialmatchgroups(items, sim_thresh=sim_thresh):\n",
    "        def strip_brackets(string):\n",
    "            string = re.sub(r\"\\(.*?\\)\", \"\", string)\n",
    "            string = re.sub(r\"\\[.*?\\]\", \"\", string)\n",
    "            return string \n",
    "        \n",
    "        items = items.copy()\n",
    "        items[\"nc\"] = items.item_name.apply(strip_brackets)\n",
    "        items[\"ncnext\"] = np.concatenate((items[\"nc\"].to_numpy()[1:],np.array([\"\"])))\n",
    "        \n",
    "        \n",
    "        def partialcompare(s):\n",
    "            return fuzz.partial_ratio(s[\"nc\"], s[\"ncnext\"])\n",
    "        \n",
    "        items[\"partialmatch\"] = items.apply(partialcompare, axis=1)\n",
    "        \n",
    "        #Assigning groups\n",
    "        grp = 0\n",
    "        for i in range(items.shape[0]):\n",
    "            items.loc[i, 'partialmatchgroup'] = grp\n",
    "            if items.loc[i, \"partialmatch\"] < sim_thresh:\n",
    "                grp += 1\n",
    "        items = items.drop(columns=[\"nc\", \"ncnext\", \"partialmatch\"])\n",
    "        return items\n",
    "    \n",
    "    items = partialmatchgroups(items)\n",
    "    items = items.rename(columns={\"partialmatchgroup\": feature_name})\n",
    "    items = items.drop(columns=\"partialmatchgroup\" , errors=\"ignore\")\n",
    "    \n",
    "    items[feature_name] = items[feature_name].apply(str)\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\n",
    "    \n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\n",
    "    \n",
    "    train = train.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\")\n",
    "    \n",
    "    return matrix, train\n",
    "\n",
    "\n",
    "matrix, train= add_item_name_groups(matrix, train, items, 65)\n",
    "\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af6265ef",
   "metadata": {
    "papermill": {
     "duration": 0.005807,
     "end_time": "2022-10-07T20:26:56.481047",
     "exception": false,
     "start_time": "2022-10-07T20:26:56.475240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "There are certain music items that would be quite difficult to use the last function on, you know, to put into similar groups. The idea is to assign music items into groups according to the artist.\n",
    "3 common patterns exist to indicate the artist's name which are:\n",
    "-His name is all in uppercase,seperated by dot & a space.\n",
    "For non-musical stuff, the items will be grouped up according to the first word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b370a329",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:56.495342Z",
     "iopub.status.busy": "2022-10-07T20:26:56.494873Z",
     "iopub.status.idle": "2022-10-07T20:26:59.509300Z",
     "shell.execute_reply": "2022-10-07T20:26:59.508193Z"
    },
    "papermill": {
     "duration": 3.024898,
     "end_time": "2022-10-07T20:26:59.512002",
     "exception": false,
     "start_time": "2022-10-07T20:26:56.487104",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "\n",
    "def add_first_word_features(matrix, items=items, feature_name=\"artist_name_or_first_word\"):\n",
    "    # This extracts artist names for music categories and adds them as a feature.\n",
    "    def extract_artist(st):\n",
    "        st = st.strip()\n",
    "        if st.startswith(\"V/A\"):\n",
    "            artist = \"V/A\"\n",
    "        elif st.startswith(\"СБ\"):\n",
    "            artist = \"СБ\"\n",
    "        else:\n",
    "            # Retrieves artist names using the double space or all uppercase pattern\n",
    "            mus_artist_dubspace = re.compile(r\".{2,}?(?=\\s{2,})\")\n",
    "            match_dubspace = mus_artist_dubspace.match(st)\n",
    "            mus_artist_capsonly = re.compile(r\"^([^a-zа-я]+\\s)+\")\n",
    "            match_capsonly = mus_artist_capsonly.match(st)\n",
    "            candidates = [match_dubspace, match_capsonly]\n",
    "            candidates = [m[0] for m in candidates if m is not None]\n",
    "            # Sometimes one of the patterns catches some extra words so choose the shortest one\n",
    "            if len(candidates):\n",
    "                artist = min(candidates, key=len)\n",
    "            else:\n",
    "                # If neither of the previous patterns found something, use the dot-space pattern\n",
    "                mus_artist_dotspace = re.compile(r\".{2,}?(?=\\.\\s)\")\n",
    "                match = mus_artist_dotspace.match(st)\n",
    "                if match:\n",
    "                    artist = match[0]\n",
    "                else:\n",
    "                    artist = \"\"\n",
    "        artist = artist.upper()\n",
    "        artist = re.sub(r\"[^A-ZА-Я ]||\\bTHE\\b\", \"\", artist)\n",
    "        artist = re.sub(r\"\\s{2,}\", \" \", artist)\n",
    "        artist = artist.strip()\n",
    "        return artist\n",
    "\n",
    "    items = items.copy()\n",
    "    all_stopwords = stopwords.words(\"russian\")\n",
    "    all_stopwords = all_stopwords + stopwords.words(\"english\")\n",
    "\n",
    "    def first_word(string):\n",
    "        # This cleans the string of special characters, excess spaces and stopwords then extracts the first word\n",
    "        string = re.sub(r\"[^\\w\\s]\", \"\", string)\n",
    "        string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "        tokens = string.lower().split()\n",
    "        tokens = [t for t in tokens if t not in all_stopwords]\n",
    "        token = tokens[0] if len(tokens) > 0 else \"\"\n",
    "        return token\n",
    "\n",
    "    music_categories = [55, 56, 57, 58, 59, 60]\n",
    "    items.loc[items.item_category_id.isin(music_categories), feature_name] = items.loc[\n",
    "        items.item_category_id.isin(music_categories), \"item_name\"\n",
    "    ].apply(extract_artist)\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other music\"\n",
    "    items.loc[~items.item_category_id.isin(music_categories), feature_name] = items.loc[\n",
    "        ~items.item_category_id.isin(music_categories), \"item_name\"\n",
    "    ].apply(first_word)\n",
    "    items.loc[items[feature_name] == \"\", feature_name] = \"other non-music\"\n",
    "    items[feature_name] = items[feature_name].factorize()[0]\n",
    "    matrix = matrix.merge(items[[\"item_id\", feature_name]], on=\"item_id\", how=\"left\",)\n",
    "    return matrix\n",
    "\n",
    "\n",
    "matrix = add_first_word_features(\n",
    "    matrix, items=items, feature_name=\"artist_name_or_first_word\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c5e0c1",
   "metadata": {
    "papermill": {
     "duration": 0.005785,
     "end_time": "2022-10-07T20:26:59.524116",
     "exception": false,
     "start_time": "2022-10-07T20:26:59.518331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Similarities also exists in the item_name field, the most notable one is their length mostly because similar items tend to have the same length.\n",
    "We're gonna use that as a feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "269731af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:26:59.538153Z",
     "iopub.status.busy": "2022-10-07T20:26:59.537745Z",
     "iopub.status.idle": "2022-10-07T20:27:02.896515Z",
     "shell.execute_reply": "2022-10-07T20:27:02.895333Z"
    },
    "papermill": {
     "duration": 3.368991,
     "end_time": "2022-10-07T20:27:02.899313",
     "exception": false,
     "start_time": "2022-10-07T20:26:59.530322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def clean_item_name(string):\n",
    "    #Removing special characters\n",
    "    string = re.sub(r\"\\[.*?\\]\", \"\", string)\n",
    "    string = re.sub(r\"\\(.*?\\)\", \"\", string)\n",
    "    string = re.sub(r\"[^A-ZА-Яa-zа-я0-9 ]\", \"\", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = string.lower()\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    string = string.lower()\n",
    "    return string\n",
    "\n",
    "items[\"item_name_cleaned_length\"] = items[\"item_name\"].apply(clean_item_name).apply(len)\n",
    "items[\"item_name_length\"] = items[\"item_name\"].apply(len)\n",
    "matrix = matrix.merge(items[['item_id', 'item_name_length', 'item_name_cleaned_length']], how='left', on='item_id')\n",
    "\n",
    "matrix = matrix.merge(items[['item_id', 'item_name_length', 'item_name_cleaned_length']], how='left', on='item_id')\n",
    "items = items.drop(columns = ['item_name_length', 'item_name_cleaned_length'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3799dd68",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-10-07T20:27:02.913330Z",
     "iopub.status.busy": "2022-10-07T20:27:02.912946Z",
     "iopub.status.idle": "2022-10-07T20:27:05.813129Z",
     "shell.execute_reply": "2022-10-07T20:27:05.811924Z"
    },
    "papermill": {
     "duration": 2.91041,
     "end_time": "2022-10-07T20:27:05.815890",
     "exception": false,
     "start_time": "2022-10-07T20:27:02.905480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created name features\n"
     ]
    }
   ],
   "source": [
    "print(\"Created name features\")\n",
    "matrix, oldcols = shrink_mem_new_cols(matrix, oldcols)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 47.111836,
   "end_time": "2022-10-07T20:27:06.644723",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2022-10-07T20:26:19.532887",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
